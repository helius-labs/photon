use sea_orm::{ConnectionTrait, DatabaseBackend, DatabaseConnection, Statement, TransactionTrait};
use serde::{Deserialize, Serialize};
use utoipa::ToSchema;

use crate::api::error::PhotonApiError;
use crate::api::method::get_multiple_new_address_proofs::{
    get_multiple_new_address_proofs_helper, AddressWithTree, MerkleContextWithNewAddressProof,
};
use crate::common::format_bytes;
use crate::common::typedefs::context::Context;
use crate::common::typedefs::hash::Hash;
use crate::common::typedefs::serializable_pubkey::SerializablePubkey;
use crate::ingester::parser::tree_info::TreeInfo;
use crate::ingester::persist::persisted_state_tree::get_subtrees;

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, ToSchema, Default)]
#[serde(deny_unknown_fields, rename_all = "camelCase")]
pub struct GetBatchAddressUpdateInfoRequest {
    pub tree: SerializablePubkey,
    pub start_queue_index: Option<u64>,
    pub limit: u16,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, ToSchema, Default)]
#[serde(deny_unknown_fields, rename_all = "camelCase")]
pub struct AddressQueueIndex {
    pub address: SerializablePubkey,
    pub queue_index: u64,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, ToSchema)]
#[serde(deny_unknown_fields, rename_all = "camelCase")]
pub struct GetBatchAddressUpdateInfoResponse {
    pub context: Context,
    pub start_index: u64,
    pub addresses: Vec<AddressQueueIndex>,
    pub non_inclusion_proofs: Vec<MerkleContextWithNewAddressProof>,
    pub subtrees: Vec<[u8; 32]>,
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, ToSchema)]
#[serde(deny_unknown_fields, rename_all = "camelCase")]
pub struct GetBatchAddressUpdateInfoResponseValue {
    pub proof: Vec<Hash>,
    pub root: Hash,
    pub leaf_index: u64,
    pub leaf: Hash,
    pub tree: Hash,
    pub root_seq: u64,
    pub tx_hash: Option<Hash>,
    pub account_hash: Hash,
}

const MAX_ADDRESSES: usize = 500;

pub async fn get_batch_address_update_info(
    conn: &DatabaseConnection,
    request: GetBatchAddressUpdateInfoRequest,
) -> Result<GetBatchAddressUpdateInfoResponse, PhotonApiError> {
    if request.limit as usize > MAX_ADDRESSES {
        return Err(PhotonApiError::ValidationError(format!(
            "Too many addresses requested {}. Maximum allowed: {}",
            request.limit, MAX_ADDRESSES
        )));
    }

    let limit = request.limit;
    let merkle_tree_pubkey = request.tree;
    let tree_info = TreeInfo::get(conn, &merkle_tree_pubkey.to_string())
        .await?
        .ok_or_else(|| PhotonApiError::UnexpectedError("Failed to get tree info".to_string()))?;

    let merkle_tree = SerializablePubkey::from(merkle_tree_pubkey.0).to_bytes_vec();

    let context = Context::extract(conn).await?;
    let tx = conn.begin().await?;
    if tx.get_database_backend() == DatabaseBackend::Postgres {
        tx.execute(Statement::from_string(
            tx.get_database_backend(),
            "SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;".to_string(),
        ))
        .await?;
    }

    // 1. Get batch_start_index
    let max_index_stmt = Statement::from_string(
        tx.get_database_backend(),
        format!(
            "SELECT COALESCE(MAX(leaf_index + 1), 1) as max_index FROM indexed_trees WHERE tree = {}",
            format_bytes(merkle_tree.clone(), tx.get_database_backend())
        ),
    );
    let max_index_result = tx.query_one(max_index_stmt).await?;
    let batch_start_index = match max_index_result {
        Some(row) => row.try_get::<i64>("", "max_index")? as usize,
        None => 1,
    };

    let offset_condition = match request.start_queue_index {
        Some(start_queue_index) => format!("AND queue_index >= {}", start_queue_index),
        None => String::new(),
    };

    // 2. Get queue elements from the address_queues table
    let address_queue_stmt = Statement::from_string(
        tx.get_database_backend(),
        format!(
            "SELECT tree, address, queue_index FROM address_queues
             WHERE tree = {}
             {}
             ORDER BY queue_index ASC
             LIMIT {}",
            format_bytes(merkle_tree.clone(), tx.get_database_backend()),
            offset_condition,
            limit
        ),
    );

    let queue_results = tx.query_all(address_queue_stmt).await?;

    // Early exit if no elements in the queue
    if queue_results.is_empty() {
        tx.commit().await?;
        return Ok(GetBatchAddressUpdateInfoResponse {
            context,
            addresses: Vec::new(),
            non_inclusion_proofs: Vec::new(),
            subtrees: Vec::new(),
            start_index: batch_start_index as u64,
        });
    }

    // 3. Build arrays for addresses and addresses with trees.
    let mut addresses = Vec::new();
    let mut addresses_with_trees = Vec::new();
    let serializable_tree = SerializablePubkey::try_from(merkle_tree.clone())?;

    for row in &queue_results {
        let address: Vec<u8> = row.try_get("", "address")?;
        let queue_index: i64 = row.try_get("", "queue_index")?;
        let address_pubkey = SerializablePubkey::try_from(address.clone())?;
        addresses_with_trees.push(AddressWithTree {
            address: address_pubkey,
            tree: serializable_tree,
        });
        addresses.push(AddressQueueIndex {
            address: address_pubkey,
            queue_index: queue_index as u64,
        });
    }

    // 4. Get non-inclusion proofs for each address.
    let non_inclusion_proofs =
        get_multiple_new_address_proofs_helper(&tx, addresses_with_trees, MAX_ADDRESSES, false)
            .await?;
    let subtrees = get_subtrees(&tx, merkle_tree, tree_info.height as usize).await?;

    Ok(GetBatchAddressUpdateInfoResponse {
        context,
        start_index: batch_start_index as u64,
        addresses,
        non_inclusion_proofs,
        subtrees,
    })
}
