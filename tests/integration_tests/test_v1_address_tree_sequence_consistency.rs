use anyhow::Result;
use futures::StreamExt;
use light_compressed_account::TreeType;
use photon_indexer::ingester::parser::{
    parse_transaction, 
    state_update::{IndexedTreeLeafUpdate, StateUpdate},
    indexer_events::MerkleTreeEvent
};
use photon_indexer::snapshot::{load_block_stream_from_directory_adapter, DirectoryAdapter};
use solana_pubkey::{pubkey, Pubkey};
use std::collections::HashMap;
use std::sync::Arc;

// V1 Address Tree Pubkey - the only v1 address tree
const V1_ADDRESS_TREE: Pubkey = pubkey!("amt1Ayt45jfbdw5YSo7iz6WZxUmnZsQTYXy82hVwyC2");

fn merkle_event_to_type_id(event: &MerkleTreeEvent) -> u8 {
    match event {
        MerkleTreeEvent::BatchAppend(_) => 1,
        MerkleTreeEvent::BatchNullify(_) => 2,
        MerkleTreeEvent::BatchAddressAppend(_) => 3,
        _ => 0, // Other event types we don't care about
    }
}

fn type_id_to_name(type_id: u8) -> &'static str {
    match type_id {
        1 => "BatchAppend",
        2 => "BatchNullify", 
        3 => "BatchAddressAppend",
        _ => "Unknown",
    }
}

#[derive(Debug, Clone)]
enum StateUpdateFieldType {
    IndexedTreeUpdate,
    LeafNullification,
    BatchNullifyContext,
    BatchNewAddress,
    BatchMerkleTreeEventAppend,
    BatchMerkleTreeEventNullify,
    BatchMerkleTreeEventAddressAppend,
    OutAccount,
}

#[derive(Debug, Clone)]
struct SequenceGap {
    // Boundary information for gap filling
    before_slot: u64,
    after_slot: u64,
    before_signature: String,
    after_signature: String,
    
    // Tree/context metadata  
    tree_pubkey: Option<Pubkey>, // Tree pubkey (unified for all tree operations)
    tree_type_string: Option<String>, // Tree type string (for indexed tree updates)
    field_type: StateUpdateFieldType,
}


#[derive(Debug, Default)]
struct StateUpdateSequences {
    // Sequences with slot and signature information for gap analysis
    indexed_tree_seqs: HashMap<(Pubkey, String), Vec<(u64, u64, String)>>, // (tree, type_string) -> (seq, slot, signature)
    nullification_seqs: HashMap<Pubkey, Vec<(u64, u64, String)>>, // tree -> (seq, slot, signature)
    batch_nullify_queue_indexes: Vec<(u64, u64, String)>, // (queue_index, slot, signature)
    batch_address_queue_indexes: HashMap<Pubkey, Vec<(u64, u64, String)>>, // tree -> (queue_index, slot, signature)
    batch_merkle_event_seqs: HashMap<(Pubkey, u8), Vec<(u64, u64, String)>>, // (tree_pubkey, event_type) -> (seq, slot, signature)
}

/// Extracts sequences from a StateUpdate with slot and signature context
fn extract_state_update_sequences(state_update: &StateUpdate, slot: u64, signature: &str) -> StateUpdateSequences {
    let mut sequences = StateUpdateSequences::default();
    
    // Extract indexed tree sequences
    for ((tree_pubkey, _), leaf_update) in &state_update.indexed_merkle_tree_updates {
        let tree_type_string = format!("{:?}", leaf_update.tree_type);
        sequences.indexed_tree_seqs
            .entry((*tree_pubkey, tree_type_string))
            .or_insert_with(Vec::new)
            .push((leaf_update.seq, slot, signature.to_string()));
    }
    
    // Extract leaf nullification sequences
    for nullification in &state_update.leaf_nullifications {
        sequences.nullification_seqs
            .entry(nullification.tree)
            .or_insert_with(Vec::new)
            .push((nullification.seq, slot, signature.to_string()));
    }
    
    // Extract batch nullify context queue indexes
    for context in &state_update.batch_nullify_context {
        sequences.batch_nullify_queue_indexes.push((context.nullifier_queue_index, slot, signature.to_string()));
    }
    
    // Extract batch new address queue indexes
    for address in &state_update.batch_new_addresses {
        sequences.batch_address_queue_indexes
            .entry(address.tree.0)
            .or_insert_with(Vec::new)
            .push((address.queue_index, slot, signature.to_string()));
    }
    
    // Extract batch merkle tree event sequences
    for (tree_hash, events) in &state_update.batch_merkle_tree_events {
        let tree_pubkey = Pubkey::from(*tree_hash);
        for (seq, merkle_event) in events {
            let event_type = merkle_event_to_type_id(merkle_event);
            if event_type > 0 {
                sequences.batch_merkle_event_seqs
                    .entry((tree_pubkey, event_type))
                    .or_insert_with(Vec::new)
                    .push((*seq, slot, signature.to_string()));
            }
        }
    }
    
    sequences
}

/// Detects gaps in a sequence with full metadata for gap filling
fn detect_sequence_gaps_with_metadata(
    sequences: &[(u64, u64, String)], // (seq, slot, signature)
    tree_pubkey: Option<Pubkey>,
    tree_type_string: Option<String>,
    field_type: StateUpdateFieldType,
) -> Vec<SequenceGap> {
    if sequences.len() < 2 {
        return Vec::new();
    }
    
    let mut sorted_sequences = sequences.to_vec();
    sorted_sequences.sort_by_key(|(seq, _, _)| *seq);
    
    let mut gaps = Vec::new();
    
    for i in 1..sorted_sequences.len() {
        let (prev_seq, prev_slot, prev_sig) = &sorted_sequences[i-1];
        let (curr_seq, curr_slot, curr_sig) = &sorted_sequences[i];
        
        if curr_seq - prev_seq > 1 {
            gaps.push(SequenceGap {
                before_slot: *prev_slot,
                after_slot: *curr_slot,
                before_signature: prev_sig.clone(),
                after_signature: curr_sig.clone(),
                tree_pubkey,
                tree_type_string: tree_type_string.clone(),
                field_type: field_type.clone(),
            });
        }
    }
    
    gaps
}


#[tokio::test]
async fn test_v1_address_tree_sequence_consistency() -> Result<()> {
    println!("ğŸ” Testing v1 Address Tree Sequence Number Consistency");
    
    // Load blocks from the created snapshot
    let snapshot_path = "/Users/ananas/dev/photon/target/snapshot_local";
    let directory_adapter = Arc::new(DirectoryAdapter::from_local_directory(snapshot_path.to_string()));
    
    println!("ğŸ“‚ Loading snapshot from: {}", snapshot_path);
    let block_stream = load_block_stream_from_directory_adapter(directory_adapter).await;
    
    // Collect all blocks from the stream
    let all_blocks: Vec<Vec<_>> = block_stream.collect().await;
    let blocks: Vec<_> = all_blocks.into_iter().flatten().collect();
    
    println!("ğŸ“¦ Processing {} blocks from snapshot", blocks.len());
    
    // Extract sequences from all StateUpdates with context
    let mut v1_address_updates: Vec<IndexedTreeLeafUpdate> = Vec::new();
    let mut all_sequences: Vec<StateUpdateSequences> = Vec::new();
    let mut total_transactions = 0;
    let mut parsed_transactions = 0;
    
    for block in blocks {
        let slot = block.metadata.slot;
        total_transactions += block.transactions.len();
        
        for transaction in &block.transactions {
            let signature = transaction.signature.to_string();
            
            // Parse each transaction to extract state updates
            match parse_transaction(transaction, slot) {
                Ok(state_update) => {
                    parsed_transactions += 1;
                    
                    // Extract v1 address tree updates for backward compatibility
                    for ((tree_pubkey, _leaf_index), leaf_update) in &state_update.indexed_merkle_tree_updates {
                        if leaf_update.tree_type == TreeType::AddressV1 && *tree_pubkey == V1_ADDRESS_TREE {
                            v1_address_updates.push(leaf_update.clone());
                        }
                    }
                    
                    // Extract sequences with context for comprehensive validation
                    let sequences = extract_state_update_sequences(&state_update, slot, &signature);
                    all_sequences.push(sequences);
                }
                Err(_) => {
                    // Skip failed parsing - compression transactions might have parsing issues
                    continue;
                }
            }
        }
    }
    
    println!("ğŸ“Š Parsed {}/{} transactions successfully", parsed_transactions, total_transactions);
    println!("ğŸŒ³ Found {} v1 address tree updates", v1_address_updates.len());
    
    if v1_address_updates.is_empty() {
        println!("âš ï¸  No v1 address tree updates found in snapshot");
        return Ok(());
    }
    
    // Sort updates by sequence number for validation
    v1_address_updates.sort_by_key(|update| update.seq);
    
    // Display first and last few updates for context
    println!("\nğŸ“‹ First 5 v1 address tree updates:");
    for (i, update) in v1_address_updates.iter().take(5).enumerate() {
        println!("  {}. seq={}, leaf_index={}, tree={}", 
                 i + 1, update.seq, update.leaf.index, update.tree);
    }
    
    if v1_address_updates.len() > 5 {
        println!("ğŸ“‹ Last 5 v1 address tree updates:");
        for (i, update) in v1_address_updates.iter().rev().take(5).enumerate() {
            let idx = v1_address_updates.len() - i;
            println!("  {}. seq={}, leaf_index={}, tree={}", 
                     idx, update.seq, update.leaf.index, update.tree);
        }
    }
    
    // Validate sequence number consistency
    println!("\nğŸ” Validating sequence number consistency...");
    
    let first_seq = v1_address_updates[0].seq;
    let last_seq = v1_address_updates.last().unwrap().seq;
    println!("ğŸ“ˆ Sequence range: {} to {} (span: {})", first_seq, last_seq, last_seq - first_seq + 1);
    
    // Check for sequential ordering starting from first sequence number
    let mut expected_seq = first_seq;
    let mut gaps = Vec::new();
    let mut is_sequential = true;
    
    for (i, update) in v1_address_updates.iter().enumerate() {
        if update.seq != expected_seq {
            gaps.push((i, expected_seq, update.seq));
            is_sequential = false;
        }
        expected_seq = update.seq + 1;
    }
    
    // Check for duplicate sequence numbers
    let mut seq_counts: HashMap<u64, usize> = HashMap::new();
    for update in &v1_address_updates {
        *seq_counts.entry(update.seq).or_insert(0) += 1;
    }
    
    let duplicates: Vec<_> = seq_counts.iter()
        .filter(|(_, &count)| count > 1)
        .map(|(&seq, &count)| (seq, count))
        .collect();
    
    // Report results
    println!("\nğŸ“Š Validation Results:");
    
    if is_sequential {
        println!("âœ… All v1 address tree sequence numbers are sequential and ascending!");
        println!("   Expected {} consecutive sequences starting from {}", 
                 v1_address_updates.len(), first_seq);
    } else {
        println!("âŒ Found {} gaps in v1 address tree sequence numbers:", gaps.len());
        for (index, expected, actual) in gaps.iter().take(10) {
            println!("   Index {}: expected seq {}, found seq {}", index, expected, actual);
        }
        if gaps.len() > 10 {
            println!("   ... and {} more gaps", gaps.len() - 10);
        }
    }
    
    if duplicates.is_empty() {
        println!("âœ… No duplicate sequence numbers found");
    } else {
        println!("âŒ Found {} duplicate sequence numbers:", duplicates.len());
        for (seq, count) in duplicates.iter().take(10) {
            println!("   Sequence {} appears {} times", seq, count);
        }
        if duplicates.len() > 10 {
            println!("   ... and {} more duplicates", duplicates.len() - 10);
        }
    }
    
    // Final assertions for the test - validate what we can guarantee
    assert!(!v1_address_updates.is_empty(), "Should have found v1 address tree updates");
    assert!(duplicates.is_empty(), "V1 address tree sequence numbers should be unique");
    
    // Report on sequence consistency (gaps may be expected due to transaction ordering)
    if is_sequential {
        println!("\nğŸ‰ V1 Address Tree sequence validation: PERFECT sequential ordering!");
    } else {
        println!("\nâœ… V1 Address Tree sequence validation completed with {} gaps detected", gaps.len());
        println!("   This may be expected behavior depending on transaction ordering in the snapshot");
    }
    
    println!("ğŸ“Š Summary: {} unique v1 address tree updates processed", v1_address_updates.len());
    
    // Comprehensive validation of all StateUpdate fields using new gap detection functions
    println!("\nğŸ” Performing comprehensive validation of all StateUpdate fields...");
    
    // Aggregate all sequences by type for gap detection
    let mut all_indexed_tree_seqs: HashMap<(Pubkey, String), Vec<(u64, u64, String)>> = HashMap::new();
    let mut all_nullification_seqs: HashMap<Pubkey, Vec<(u64, u64, String)>> = HashMap::new();
    let mut all_batch_nullify_queue_indexes: Vec<(u64, u64, String)> = Vec::new();
    let mut all_batch_address_queue_indexes: HashMap<Pubkey, Vec<(u64, u64, String)>> = HashMap::new();
    let mut all_batch_merkle_event_seqs: HashMap<(Pubkey, u8), Vec<(u64, u64, String)>> = HashMap::new();
    
    // Aggregate sequences from all extracted StateUpdateSequences
    for sequences in &all_sequences {
        // Merge indexed tree sequences
        for ((tree, tree_type_string), seqs) in &sequences.indexed_tree_seqs {
            all_indexed_tree_seqs.entry((*tree, tree_type_string.clone())).or_insert_with(Vec::new).extend(seqs.clone());
        }
        
        // Merge nullification sequences
        for (tree, seqs) in &sequences.nullification_seqs {
            all_nullification_seqs.entry(*tree).or_insert_with(Vec::new).extend(seqs.clone());
        }
        
        // Merge batch nullify queue indexes
        all_batch_nullify_queue_indexes.extend(sequences.batch_nullify_queue_indexes.clone());
        
        // Merge batch address queue indexes
        for (tree, seqs) in &sequences.batch_address_queue_indexes {
            all_batch_address_queue_indexes.entry(*tree).or_insert_with(Vec::new).extend(seqs.clone());
        }
        
        // Merge batch merkle event sequences
        for ((tree, event_type), seqs) in &sequences.batch_merkle_event_seqs {
            all_batch_merkle_event_seqs.entry((*tree, *event_type)).or_insert_with(Vec::new).extend(seqs.clone());
        }
    }
    
    // Detect gaps using the new functions
    let mut total_gaps = 0;
    
    // Check indexed tree updates
    for ((tree_pubkey, tree_type_string), sequences) in &all_indexed_tree_seqs {
        let gaps = detect_sequence_gaps_with_metadata(
            sequences,
            Some(*tree_pubkey),
            Some(tree_type_string.clone()),
            StateUpdateFieldType::IndexedTreeUpdate,
        );
        if !gaps.is_empty() {
            println!("âŒ Found {} gaps in indexed tree updates for tree {} (type {})", gaps.len(), tree_pubkey, tree_type_string);
            total_gaps += gaps.len();
        } else {
            println!("âœ… No gaps in indexed tree updates for tree {} (type {}) - {} sequences", tree_pubkey, tree_type_string, sequences.len());
        }
    }
    
    // Check leaf nullifications
    for (tree_pubkey, sequences) in &all_nullification_seqs {
        let gaps = detect_sequence_gaps_with_metadata(
            sequences,
            Some(*tree_pubkey),
            None,
            StateUpdateFieldType::LeafNullification,
        );
        if !gaps.is_empty() {
            println!("âŒ Found {} gaps in leaf nullifications for tree {}", gaps.len(), tree_pubkey);
            total_gaps += gaps.len();
        } else {
            println!("âœ… No gaps in leaf nullifications for tree {} - {} sequences", tree_pubkey, sequences.len());
        }
    }
    
    // Check batch nullify context
    if !all_batch_nullify_queue_indexes.is_empty() {
        let gaps = detect_sequence_gaps_with_metadata(
            &all_batch_nullify_queue_indexes,
            None,
            None,
            StateUpdateFieldType::BatchNullifyContext,
        );
        if !gaps.is_empty() {
            println!("âŒ Found {} gaps in batch nullify context queue indexes", gaps.len());
            total_gaps += gaps.len();
        } else {
            println!("âœ… No gaps in batch nullify context queue indexes - {} sequences", all_batch_nullify_queue_indexes.len());
        }
    }
    
    // Check batch new addresses
    for (tree_pubkey, sequences) in &all_batch_address_queue_indexes {
        let gaps = detect_sequence_gaps_with_metadata(
            sequences,
            Some(*tree_pubkey),
            None,
            StateUpdateFieldType::BatchNewAddress,
        );
        if !gaps.is_empty() {
            println!("âŒ Found {} gaps in batch new addresses for tree {}", gaps.len(), tree_pubkey);
            total_gaps += gaps.len();
        } else {
            println!("âœ… No gaps in batch new addresses for tree {} - {} sequences", tree_pubkey, sequences.len());
        }
    }
    
    // Check batch merkle tree events
    for ((tree_pubkey, event_type), sequences) in &all_batch_merkle_event_seqs {
        let field_type = match event_type {
            1 => StateUpdateFieldType::BatchMerkleTreeEventAppend,
            2 => StateUpdateFieldType::BatchMerkleTreeEventNullify,
            3 => StateUpdateFieldType::BatchMerkleTreeEventAddressAppend,
            _ => continue,
        };
        
        let gaps = detect_sequence_gaps_with_metadata(
            sequences,
            Some(*tree_pubkey),
            None,
            field_type,
        );
        if !gaps.is_empty() {
            println!("âŒ Found {} gaps in batch merkle tree events for tree {} (event type {})", gaps.len(), tree_pubkey, event_type);
            total_gaps += gaps.len();
        } else {
            println!("âœ… No gaps in batch merkle tree events for tree {} (event type {}) - {} sequences", tree_pubkey, event_type, sequences.len());
        }
    }
    
    println!("\nğŸ“Š Comprehensive validation summary:");
    println!("   Total gaps found across all StateUpdate fields: {}", total_gaps);
    if total_gaps == 0 {
        println!("ğŸ‰ All StateUpdate sequences are perfectly consistent!");
    } else {
        println!("âš ï¸  Found {} gaps that may need investigation or gap filling", total_gaps);
    }
    
    println!("\nğŸ‰ Comprehensive StateUpdate validation completed!");
    
    Ok(())
}

